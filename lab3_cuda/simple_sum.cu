
#include "cuda_runtime.h"
#include "device_launch_parameters.h"
#include <stdio.h>


// nvcc -o simple_sum simple_sum.cu 


#define REAL float
#define uint unsigned int 

__global__ void add(REAL* a, REAL* b, REAL* c, uint N){

	uint index = blockIdx.x *blockDim.x + threadIdx.x; //Calculate the data at the index

	if(index < N)
		c[index] = a[index] + b[index];

}

int main(void){

	REAL *a, *b, *c;
	REAL *dev_a, *dev_b, *dev_c;
	uint N = 10;

    cudaMalloc((void**)&a, N * sizeof(REAL));
	cudaMalloc((void**)&b, N * sizeof(REAL));
	cudaMalloc((void**)&c, N * sizeof(REAL));
	
	 // Assign values ​​to the arrays ‘a’ and ‘b’ on the cpu
	 //Why do you want to assign a value to the input array on the CPU, there is actually no special reason?
	 //Assuming that it is used to read data from the hard disk, or is a step in other applications, and the input array is generated by other algorithms
	for (int i = 0; i<N; i++) {
		a[i] = -i; b[i] = i * i;
	}
	 //1. Allocate memory on the GPU
	cudaMalloc((void**)&dev_a, N * sizeof(REAL));
	cudaMalloc((void**)&dev_b, N * sizeof(REAL));
	cudaMalloc((void**)&dev_c, N * sizeof(REAL));
 
	 //2. Copy the arrays ‘a’ and ‘b’ to the GPU
	cudaMemcpy(dev_a, a, N * sizeof(int), cudaMemcpyHostToDevice);
	cudaMemcpy(dev_b, b, N * sizeof(int), cudaMemcpyHostToDevice);
 
	 //3. Execute the kernel
	dim3 BS(N);
	dim3 GS(ceil(N/(float)BS.x));

	add<<<BS, GS>>>(dev_a,dev_b,dev_c, N);
 
	 //4. Copy the array ‘c’ from GPU to CPU
	cudaMemcpy(c, dev_c, N * sizeof(int), cudaMemcpyDeviceToHost);
 
	 //Display the result on the CPU
	for (int i = 0; i<N; i++) {
		printf("%f + %f = %f\n", a[i], b[i], c[i]);
	}
 
	 //5. Release the memory allocated on the GPU. Purpose to avoid memory leaks
	cudaFree(dev_a);
	cudaFree(dev_b);
	cudaFree(dev_c);
 
	return 0;
}
