
#include <cstdlib>
#include <cuda_runtime.h>
#include <stdio.h>

 //////////////////////////////////////////////////////////////////

#define CHECK_CUDA_ERROR(val) check((val), #val, __FILE__, __LINE__)
template <typename T>
void check(T err, const char* const func, const char* const file, const int line)
{
    if (err != cudaSuccess)
    {
		printf("CUDA Runtime Error at: %s:%d\n", file, line);
		printf("%s %s\n", cudaGetErrorString(err), func);
		exit(err);
    }
}

#define CHECK_LAST_CUDA_ERROR() checkLast(__FILE__, __LINE__)
void checkLast(const char* const file, const int line)
{
    cudaError_t err{cudaGetLastError()};
    if (err != cudaSuccess)
    {
       	printf("CUDA Runtime Error at: %s:%d\n", file, line);
		printf("%s\n", cudaGetErrorString(err));
    }
}

 //////////////////////////////////////////////////////////////////

// nvcc -o simple_sum simple_sum.cu 


#define REAL float
#define uint unsigned int 

__global__ void add(REAL* a, REAL* b, REAL* c, uint N){

	uint index = blockIdx.x *blockDim.x + threadIdx.x; //Calculate the data at the index

	if(index < N)
		c[index] = a[index] + b[index];

}

int main(void){

	REAL *a, *b, *c;
	REAL *dev_a, *dev_b, *dev_c;
	uint N = 10;

    cudaMalloc((void**)&a, N * sizeof(REAL));
	cudaMalloc((void**)&b, N * sizeof(REAL));
	cudaMalloc((void**)&c, N * sizeof(REAL));
	
	 // Assign values ​​to the arrays ‘a’ and ‘b’ on the cpu
	 //Why do you want to assign a value to the input array on the CPU, there is actually no special reason?
	 //Assuming that it is used to read data from the hard disk, or is a step in other applications, and the input array is generated by other algorithms
	for (int i = 0; i<N; i++) {
		a[i] = -i; b[i] = i * i;
	}
	 //1. Allocate memory on the GPU
	CHECK_CUDA_ERROR(cudaMalloc(&dev_a, N * sizeof(REAL)));
	CHECK_CUDA_ERROR(cudaMalloc(&dev_b, N * sizeof(REAL)));
	CHECK_CUDA_ERROR(cudaMalloc(&dev_c, N * sizeof(REAL)));
 
	 //2. Copy the arrays ‘a’ and ‘b’ to the GPU
	CHECK_CUDA_ERROR(cudaMemcpy(dev_a, a, N * sizeof(int), cudaMemcpyHostToDevice));
	CHECK_CUDA_ERROR(cudaMemcpy(dev_b, b, N * sizeof(int), cudaMemcpyHostToDevice));
 
	 //3. Execute the kernel
	dim3 BS(N);
	dim3 GS(ceil(N/(float)BS.x));

	add<<<BS, GS>>>(dev_a,dev_b,dev_c, N);
 
	 //4. Copy the array ‘c’ from GPU to CPU
	CHECK_CUDA_ERROR(cudaMemcpy(c, dev_c, N * sizeof(int), cudaMemcpyDeviceToHost));
 
	 //Display the result on the CPU
	for (int i = 0; i<N; i++) {
		printf("%f + %f = %f\n", a[i], b[i], c[i]);
	}
 
	 //5. Release the memory allocated on the GPU. Purpose to avoid memory leaks
	cudaFree(dev_a);
	cudaFree(dev_b);
	cudaFree(dev_c);
	CHECK_LAST_CUDA_ERROR();
 
	return 0;
}
