# Отчёт Лаб 3: Уравнение теплопроводности (CUDA)

## Задание

Реализовать решение уравнение теплопроводности (пятиточечный шаблон) в двумерной области на  равномерных сетках (128^2, 256^2, 512^2, 1024^2). Граничные условия – линейная интерполяция между углами области. Значение в углах – 10, 20, 30, 20. Ограничить точность – 10^-6 и максимальное число итераций – 10^6.

Параметры (точность, размер сетки, количество итераций) должны задаваться через параметры командной строки.

Вывод программы - количество итераций и достигнутое значение ошиибки.

Перенести программу на GPU используя CUDA. Операцию редукции (подсчет максимальной ошибки) реализовать с использованием библиотеки CUB.
Сравнить скорость работы для разных размеров сеток на графическом процессоре с  предыдущей реализацией на OpenACC.

## Результат

### Реализованные функции (heatCUDA.cu)

```C++

//Функции для отслеживания ошибок cuda
#define CHECK_CUDA_ERROR(val) check((val), #val, __FILE__, __LINE__)
template <typename T>
void check(T, const char* const, const char* const, const int);

#define CHECK_LAST_CUDA_ERROR() checkLast(__FILE__, __LINE__)
void checkLast(const char* const, const int);


//Функция для перевода 2D индексов в 1D
int __host__ __device__ ind2D(const size_t, const size_t, const size_t);

//Итерационный шаг (gpu)
__global__ void step_estimate(REAL*, REAL*, size_t);

//Функция для вычисления квадрата L2 нормы (gpu)
__global__ void square_sum(REAL*  T, REAL *v_norm, size_t N)

//Функция для вычисления разности двух массивов (gpu)
__global__ void sub(REAL*, REAL*, REAL*, size_t)

//Функция для вычисления копирования значений массива (gpu)
__global__ void copy(REAL*, REAL*, size_t);


// Функция для инициализации граничных условий
void init_border(uint, REAL**, REAL, REAL, REAL, REAL);

//Функция для вычисления L2 нормы (cpu)
REAL norm_cpu(REAL*, uint)

//Вывод 2D массива в консоль
void print2D(REAL*, size_t, size_t)

```

### Не понятные моменты

Что мне выводит программа после запуска

```bash
Input params(tol = 9.00e-06, N = 4, max_iter = 30)
1.0000 1.0000 1.0000 1.0000 
1.0000 0.0000 0.0000 1.0000 
1.0000 0.0000 0.0000 1.0000 
1.0000 1.0000 1.0000 1.0000 
threads: 1, block size: 4

iter: 0

new_T
0.5000 0.7500 0.7500 0.7500 
0.5000 0.5000 0.5000 0.5000 
0.5000 0.5000 0.5000 0.5000 
0.7500 0.7500 0.7500 0.5000 

||new_T|| (cpu): 2.423840 
||new_T|| (gpu): 0.750000 
err ||new_T|| (cpu) != ||new_T|| (gpu)


subT = T - new_T
0.5000 0.2500 0.2500 0.2500 
0.5000 -0.5000 -0.5000 0.5000 
0.5000 -0.5000 -0.5000 0.5000 
0.2500 0.2500 0.2500 0.5000 

diff (||subT||): 0.250000 


iter: 1

new_T
0.3125 0.6250 0.6875 0.5000 
0.3750 0.5625 0.5625 0.4375 
0.4375 0.5625 0.5625 0.3750 
0.5000 0.6875 0.6250 0.3125 

||new_T|| (cpu): 2.086040 
||new_T|| (gpu): 0.838525 
err ||new_T|| (cpu) != ||new_T|| (gpu)


subT = T - new_T
0.1875 0.1250 0.0625 0.2500 
0.1250 -0.0625 -0.0625 0.0625 
0.0625 -0.0625 -0.0625 0.1250 
0.2500 0.0625 0.1250 0.1875 

diff (||subT||): 0.279509 


iter: 2

new_T
0.2500 0.5156 0.5938 0.4375 
0.3281 0.5312 0.5625 0.3594 
0.3594 0.5625 0.5312 0.3281 
0.4375 0.5938 0.5156 0.2500 

||new_T|| (cpu): 1.848114 
||new_T|| (gpu): 0.900439 
err ||new_T|| (cpu) != ||new_T|| (gpu)


subT = T - new_T
0.0625 0.1094 0.0938 0.0625 
0.0469 0.0312 0.0000 0.0781 
0.0781 0.0000 0.0312 0.0469 
0.0625 0.0938 0.1094 0.0625 

diff (||subT||): 0.283412 


iter: 3

new_T
0.2109 0.4531 0.5273 0.3672 
0.2852 0.4922 0.5039 0.3320 
0.3320 0.5039 0.4922 0.2852 
0.3672 0.5273 0.4531 0.2109 

||new_T|| (cpu): 1.643450 
||new_T|| (gpu): 0.944513 
err ||new_T|| (cpu) != ||new_T|| (gpu)


subT = T - new_T
0.0391 0.0625 0.0664 0.0703 
0.0430 0.0391 0.0586 0.0273 
0.0273 0.0586 0.0391 0.0430 
0.0703 0.0664 0.0625 0.0391 

diff (||subT||): 0.286651 


...


iter: 30

new_T
0.0088 0.0191 0.0222 0.0155 
0.0124 0.0213 0.0222 0.0141 
0.0141 0.0222 0.0213 0.0124 
0.0155 0.0222 0.0191 0.0088 

||new_T|| (cpu): 0.070332 
||new_T|| (gpu): 1.122950 
err ||new_T|| (cpu) != ||new_T|| (gpu)


subT = T - new_T
0.0011 0.0024 0.0027 0.0019 
0.0015 0.0026 0.0027 0.0017 
0.0017 0.0027 0.0026 0.0015 
0.0019 0.0027 0.0024 0.0011 

diff (||subT||): 0.294656 


0.0088 0.0191 0.0222 0.0155 
0.0124 0.0213 0.0222 0.0141 
0.0141 0.0222 0.0213 0.0124 
0.0155 0.0222 0.0191 0.0088 
```

Я хочу сделать корректную функцию для подсчёта суммы квадратов, чтоб можно было считать норму разности двух степов. Пока что я не понимаю как сделать общий сумматор для всех ядер (да и в целом как делать функции, которые могли бы выдавать скалярный результат).
Пока что умею работать только с большими массивами (сумма, разность, копирование значений)

Сумму квадратов я реализую с помощью функции `square_sum` (heatCUDA.cu строчки 60-72): Она принимает аргументом массив со значениями и массив (из одной ячейки) куда я хочу сохранить сумму. Так же я отдельно перевожу массив с `gpu` на `процессор` и считаю квадрат суммы на `CPU`.
**Но пока что эти значения не совпадают. Возможно я как-то не правильно суммирую и там происходят конфликты при паралеллном суммировании.**

Вот здесь я делаю проверку того, что вычисления на `GPU` через ядра даёт (пока что не даёт) тот же результат, что и на `CPU`.

heatCUDA.cu (строчки 189-208)
```C++
///////////////////////////////////////////////////////////////////////
//Print new estimate (for debug)

CHECK_CUDA_ERROR(cudaMemcpy(new_T,  dev_nT, FULL_MEM_SIZE, cudaMemcpyDeviceToHost)); //DeviceToHost
printf("\nnew_T\n");
print2D(new_T, N, N);
printf("\n");
norm_nT = norm_cpu(new_T, N); // L2 norm calculation
printf("||new_T|| (cpu): %f \n", norm_nT);

// Calculate norm of estimate on GPU
square_sum<<<GS, BS>>>(dev_nT, norm_dev_nT, N); // CUDA kernel (save sum result fron Device (norm_dev_nT) to Host (norm_nT_gpu) )
CHECK_CUDA_ERROR(cudaMemcpy(&norm_nT_gpu,  &norm_dev_nT[0], sizeof(REAL), cudaMemcpyDeviceToHost));
norm_nT_gpu = std::sqrt(norm_nT_gpu);
printf("||new_T|| (gpu): %f \n", norm_nT_gpu);

if (norm_nT != norm_nT_gpu) // Check correct (error !!!)
    printf("err ||new_T|| (cpu) != ||new_T|| (gpu)\n");

/////////////////////////////////////////////////////////////////////// 
```
